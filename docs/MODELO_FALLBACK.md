# Sistema de Fallback de Modelos IA

## ğŸ¯ Objetivo

Garantir que o chat AI continue funcionando mesmo quando o modelo premium (Llama 3.3 70B) atinge o limite diÃ¡rio de tokens, alternando automaticamente para o modelo econÃ´mico (Llama 3.1 8B).

## ğŸš€ Como Usar

### SeleÃ§Ã£o Manual

No chat, vocÃª verÃ¡ um dropdown no topo da Ã¡rea de input:

```
ğŸ¤– Modelo: [Dropdown â–¼]
  â€¢ Llama 3.3 70B (Premium) - Melhor qualidade
  â€¢ Llama 3.1 8B (RÃ¡pido) - Mais econÃ´mico
```

**Para trocar manualmente:**
1. Clique no dropdown
2. Selecione o modelo desejado
3. Sua preferÃªncia Ã© salva automaticamente
4. Continue a conversa normalmente - o histÃ³rico permanece!

### Fallback AutomÃ¡tico

O sistema tem **3 pontos de detecÃ§Ã£o**:

#### 1. Ao Abrir o Chat (DetecÃ§Ã£o Inicial)
```
ğŸ” Sistema testa modelo premium em background
   â”œâ”€ DisponÃ­vel â†’ Usa 70B
   â””â”€ Rate limit â†’ Troca para 8B automaticamente
```

**Mensagem exibida:**
```
âš¡ Modelo premium atingiu limite diÃ¡rio. Usando Llama 3.1 8B (rÃ¡pido e funcional)!

OlÃ¡! Estou aqui para ajudar com o projeto...
```

#### 2. Durante a ConversaÃ§Ã£o
Se vocÃª estÃ¡ usando 70B e atinge o limite:

```
[UsuÃ¡rio envia mensagem]
   â†“
[Sistema detecta erro 429]
   â†“
[Troca automaticamente para 8B]
   â†“
[Exibe mensagem de troca]
   â†“
[UsuÃ¡rio reenvia mensagem com novo modelo]
```

**Mensagem exibida:**
```
âš¡ Modelo premium atingiu limite. Mudando automaticamente para Llama 3.1 8B 
(mais rÃ¡pido e econÃ´mico). VocÃª pode mudar manualmente depois.
```

#### 3. Troca Manual Preventiva
VocÃª pode trocar antes de atingir o limite:
- Use o dropdown para selecionar 8B
- Economize tokens do 70B para tarefas mais complexas
- 8B Ã© 3x mais rÃ¡pido!

## ğŸ“Š ComparaÃ§Ã£o de Modelos

### Llama 3.3 70B (Premium)

**Quando usar:**
- âœ… Projetos complexos com muitas seÃ§Ãµes
- âœ… Precisa de explicaÃ§Ãµes muito detalhadas
- âœ… Primeira vez criando estrutura de GDD
- âœ… Quer sugestÃµes mais elaboradas

**CaracterÃ­sticas:**
- 70 bilhÃµes de parÃ¢metros
- Respostas mais longas e detalhadas
- Melhor compreensÃ£o de contexto
- ~14K tokens por minuto
- Ideal para brainstorming

**Exemplo de resposta:**
```
Dahora! Vou estruturar o sistema de combate considerando 
a arquitetura do seu jogo e as melhores prÃ¡ticas de GDD.

ğŸ“Š Sistema de Combate (seÃ§Ã£o principal)
   â”œâ”€ âš”ï¸ MecÃ¢nicas BÃ¡sicas
   â”‚   â””â”€ Ataques, defesa, esquiva, stamina
   â”œâ”€ ğŸ¯ Sistema de Alvo
   â”‚   â””â”€ Mira assistida, troca rÃ¡pida, priorizaÃ§Ã£o
   â”œâ”€ ğŸ’¥ Combos e Habilidades Especiais
   â”‚   â””â”€ Encadeamento, inputs, cooldowns
   â””â”€ âš–ï¸ Balanceamento
       â””â”€ Curva de dificuldade, progressÃ£o de dano

Por que essa estrutura? [explicaÃ§Ã£o detalhada...]

Vou criar conteÃºdo rico com exemplos de mecÃ¢nicas similares 
em outros jogos e referÃªncias cruzadas com $[Sistema de Itens].

Digite 'sim' para eu executar! âœ¨
```

### Llama 3.1 8B (RÃ¡pido)

**Quando usar:**
- âœ… JÃ¡ conhece o sistema, sÃ³ quer executar
- âœ… Tarefas simples (criar, editar, remover)
- âœ… Precisa de velocidade
- âœ… Quer economizar tokens
- âœ… Modelo premium atingiu limite

**CaracterÃ­sticas:**
- 8 bilhÃµes de parÃ¢metros
- Respostas mais diretas e concisas
- 3x mais rÃ¡pido
- ~30K tokens por minuto
- Mesma funcionalidade de comandos

**Exemplo de resposta:**
```
Show! Vou criar sistema de combate:

ğŸ“Š Sistema de Combate
   â”œâ”€ âš”ï¸ MecÃ¢nicas BÃ¡sicas
   â”œâ”€ ğŸ¯ Sistema de Alvo  
   â”œâ”€ ğŸ’¥ Combos
   â””â”€ âš–ï¸ Balanceamento

Estrutura padrÃ£o com referÃªncias ao $[Sistema de Itens].

Digite 'sim' pra eu criar! âœ¨
```

**Ambos executam comandos perfeitamente:**
```
[EXECUTAR]
CRIAR: Sistema de Combate | ConteÃºdo...
SUBSECAO: MecÃ¢nicas BÃ¡sicas | Sistema de Combate | ConteÃºdo...
```

## ğŸ”„ Fluxo Completo

### CenÃ¡rio 1: Primeiro Uso (70B disponÃ­vel)

```
1. UsuÃ¡rio: Abre projeto "Meu RPG"
2. Sistema: Testa 70B em background
3. Sistema: 70B disponÃ­vel âœ…
4. Chat: "OlÃ¡! Estou aqui para ajudar com Meu RPG..."
5. Dropdown: Mostra "Llama 3.3 70B (Premium)" selecionado
6. UsuÃ¡rio: "Cria seÃ§Ãµes sobre combate"
7. IA 70B: [Resposta detalhada com estrutura completa]
```

### CenÃ¡rio 2: 70B Atingiu Limite (DetecÃ§Ã£o Inicial)

```
1. UsuÃ¡rio: Abre projeto "Meu RPG"
2. Sistema: Testa 70B em background
3. Sistema: 70B retorna erro 429 âŒ
4. Sistema: Troca automaticamente para 8B
5. Chat: "âš¡ Modelo premium atingiu limite. Usando 8B..."
6. Dropdown: Mostra "Llama 3.1 8B (RÃ¡pido)" + badge "âš¡ Mudado automaticamente"
7. UsuÃ¡rio: "Cria seÃ§Ãµes sobre combate"
8. IA 8B: [Resposta concisa mas funcional]
```

### CenÃ¡rio 3: Rate Limit Durante Conversa

```
1. UsuÃ¡rio: EstÃ¡ conversando com 70B
2. UsuÃ¡rio: "Adiciona mais detalhes ao combate"
3. Sistema: Envia requisiÃ§Ã£o para 70B
4. API: Retorna erro 429 (rate limit)
5. Sistema: Detecta erro, troca para 8B
6. Chat: Mostra mensagem "âš¡ Limite atingido, mudando para 8B..."
7. Sistema: Remove mensagem de "Pensando..."
8. UsuÃ¡rio: Reenvia mensagem
9. IA 8B: Responde com 8B agora
```

### CenÃ¡rio 4: Troca Manual

```
1. UsuÃ¡rio: EstÃ¡ conversando com 70B
2. UsuÃ¡rio: Clica no dropdown
3. UsuÃ¡rio: Seleciona "Llama 3.1 8B (RÃ¡pido)"
4. Sistema: Salva preferÃªncia no localStorage
5. Sistema: Remove badge "Mudado automaticamente" se existir
6. Chat: Continua normalmente
7. PrÃ³ximas mensagens: Usam 8B
8. HistÃ³rico: Mantido completamente
```

## ğŸ’¾ PersistÃªncia

### O que Ã© salvo?

```javascript
// localStorage
{
  "ai-model-preference": "llama-3.1-8b-instant"
}
```

### Quando Ã© salvo?

- âœ… Ao trocar manualmente via dropdown
- âŒ NÃƒO salva quando troca automÃ¡tica (fallback)
  - Motivo: Quando 70B resetar, usuÃ¡rio vai querer usÃ¡-lo novamente

### Quando Ã© carregado?

- Ao abrir o chat
- ApÃ³s recarregar a pÃ¡gina
- Em nova sessÃ£o do navegador (mesmo domÃ­nio)

### Como resetar?

1. **Via UI:** Selecione o modelo desejado no dropdown
2. **Via DevTools:**
   ```javascript
   localStorage.removeItem('ai-model-preference');
   location.reload();
   ```

## ğŸ› Troubleshooting

### "Sempre usa 8B mesmo sem rate limit"

**Causa:** PreferÃªncia salva no localStorage  
**SoluÃ§Ã£o:** Troque manualmente para 70B via dropdown

### "NÃ£o detecta rate limit"

**Verificar:**
1. Console do navegador - deve mostrar: `API Error: 429`
2. Terminal do servidor - deve mostrar erro Groq
3. Mensagem de erro no chat

**Se nÃ£o detectar:**
- Verifique se `response.status === 429`
- Confirme que erro contÃ©m `rate_limit_exceeded`

### "Dropdown nÃ£o aparece"

**Verificar:**
1. Componente AIChat renderizado?
2. CSS carregado corretamente?
3. Estado `selectedModel` inicializado?

### "Conversa some ao trocar modelo"

**Isso nÃ£o deveria acontecer!**  
Estado `messages` Ã© mantido ao trocar modelo.

**Debug:**
```javascript
// Em AIChat.tsx
console.log('Messages:', messages);
console.log('Selected model:', selectedModel);
```

### "Teste inicial demora muito"

Normal! O teste inicial:
- Faz requisiÃ§Ã£o para API
- Espera resposta ou timeout
- NÃ£o bloqueia UI
- Acontece apenas uma vez

**Para acelerar:**
- Use modelo 8B manualmente desde o inÃ­cio
- Ou desabilite teste inicial (nÃ£o recomendado)

## ğŸ› ï¸ PersonalizaÃ§Ã£o

### Desabilitar DetecÃ§Ã£o AutomÃ¡tica Inicial

Em `AIChat.tsx`, comente o useEffect:

```typescript
// useEffect(() => {
//   const testModelAvailability = async () => {
//     ...
//   };
//   testModelAvailability();
// }, []);
```

### Adicionar Novos Modelos

1. Em `utils/ai/client.ts`:
```typescript
export const GROQ_MODELS = {
  PREMIUM: 'llama-3.3-70b-versatile',
  FAST: 'llama-3.1-8b-instant',
  NOVO: 'novo-modelo-groq', // Adicione aqui
} as const;
```

2. Em `AIChat.tsx`, adicione option:
```tsx
<option value="novo-modelo-groq">
  Novo Modelo - DescriÃ§Ã£o
</option>
```

### Mudar Ordem de Fallback

Em `AIChat.tsx`, troque ordem:

```typescript
// Fallback: 70B â†’ 8B (atual)
if (selectedModel === 'llama-3.3-70b-versatile') {
  setSelectedModel('llama-3.1-8b-instant');
}

// Fallback: 8B â†’ 70B (reverso)
if (selectedModel === 'llama-3.1-8b-instant') {
  setSelectedModel('llama-3.3-70b-versatile');
}
```

## ğŸ“ˆ MÃ©tricas

### Como Monitorar Uso

1. **Groq Console:**
   - https://console.groq.com/
   - Dashboard â†’ Usage
   - GrÃ¡fico de tokens por modelo

2. **Logs do Servidor:**
   ```
   Error: API error: 429 - {
     "error": {
       "message": "Rate limit reached...",
       "Used": 98949,
       "Requested": 3477
     }
   }
   ```

3. **Console do Navegador:**
   ```
   API Error: 429 [detalhes do erro]
   Rate limit no modelo premium, tentando modelo rÃ¡pido...
   ```

### Calcular Economia

```
Tokens economizados = (Msgs com 8B) Ã— (Avg tokens 70B - Avg tokens 8B)

Exemplo:
- 10 mensagens com 70B: ~500 tokens cada = 5000 tokens
- 10 mensagens com 8B: ~200 tokens cada = 2000 tokens
- Economia: 3000 tokens (60%)
```

## ğŸ“ Boas PrÃ¡ticas

### Use 70B para:
- ğŸ¨ Brainstorming inicial
- ğŸ“š Aprender sobre GDD
- ğŸ—ï¸ Estruturar projeto novo
- ğŸ¤” DecisÃµes de design complexas

### Use 8B para:
- âš¡ Criar seÃ§Ãµes simples
- âœï¸ Editar conteÃºdo
- ğŸ—‘ï¸ Remover seÃ§Ãµes
- ğŸ”„ Tarefas repetitivas
- ğŸ’° Economizar tokens

### EstratÃ©gia HÃ­brida:
1. **InÃ­cio do dia:** Use 70B para planejamento
2. **Durante o dia:** Use 8B para execuÃ§Ã£o
3. **Fim do dia:** Volte para 70B se necessÃ¡rio
4. **PrÃ³ximo dia:** Rate limit resetou, comece com 70B

## ğŸ”’ SeguranÃ§a

### Dados SensÃ­veis

Ambos os modelos:
- âœ… Rodam na API Groq (nÃ£o localmente)
- âœ… Seguem polÃ­ticas de privacidade Groq
- âœ… NÃ£o armazenam conversas permanentemente
- âœ… localStorage apenas guarda preferÃªncia de modelo (nÃ£o conteÃºdo)

### API Key

- âš ï¸ Nunca comite `.env.local`
- âš ï¸ Use variÃ¡veis de ambiente
- âš ï¸ Rotacione keys periodicamente
- âœ… Keys sÃ£o server-side apenas (Next.js API routes)

## ğŸ“š ReferÃªncias

- [Groq Documentation](https://console.groq.com/docs)
- [Llama 3.3 70B Model Card](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct)
- [Llama 3.1 8B Model Card](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct)
- [Rate Limits Guide](./RATE_LIMITS.md)
